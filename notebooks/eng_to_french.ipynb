{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7f95dc89",
      "metadata": {
        "id": "7f95dc89"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer , tokenizer_from_json\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2b9ab100",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b9ab100",
        "outputId": "bda1a4d6-8562-4a21-ac91-81bab5a4bd21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/devicharith/language-translation-englishfrench?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.51M/3.51M [00:00<00:00, 165MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/devicharith/language-translation-englishfrench/versions/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"devicharith/language-translation-englishfrench\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2b878f66",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b878f66",
        "outputId": "66a03354-f339-40a6-a3d1-ba654f8fb38a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   English                  French\n",
            "0  English words/sentences  French words/sentences\n",
            "1                      Hi.                  Salut!\n",
            "2                     Run!                 Cours !\n",
            "3                     Run!                Courez !\n",
            "4                     Who?                   Qui ?\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"/root/.cache/kagglehub/datasets/devicharith/language-translation-englishfrench/versions/2/eng_-french.csv\",names=[\"English\",\"French\"])\n",
        "english_sentences = data[\"English\"].tolist()\n",
        "french_sentences = data[\"French\"].tolist()\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b75682a6",
      "metadata": {
        "id": "b75682a6"
      },
      "outputs": [],
      "source": [
        "tokenizer_eng = Tokenizer()\n",
        "tokenizer_eng.fit_on_texts(english_sentences)\n",
        "eng_seq = tokenizer_eng.texts_to_sequences(english_sentences)\n",
        "\n",
        "tokenizer_fr = Tokenizer()\n",
        "tokenizer_fr.fit_on_texts(french_sentences)\n",
        "fr_seq = tokenizer_fr.texts_to_sequences(french_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bc17628f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc17628f",
        "outputId": "ae82dafc-199f-4e42-e9a7-1a06a55fcadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[291, 634, 3272], [2818], [429], [429], [79]]\n",
            "[[18607, 18608, 18609], [4241], [6947], [18610], [32]]\n"
          ]
        }
      ],
      "source": [
        "print(eng_seq[0:5])\n",
        "print(fr_seq[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "bfa30928",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfa30928",
        "outputId": "22a4fea4-dabc-44a9-c3e2-11688534263b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14532\n",
            "30664\n"
          ]
        }
      ],
      "source": [
        "vocab_size_eng = len(tokenizer_eng.word_index) + 1\n",
        "vocab_size_fr = len(tokenizer_fr.word_index) + 1\n",
        "print(vocab_size_eng)\n",
        "print(vocab_size_fr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ac4448a5",
      "metadata": {
        "id": "ac4448a5"
      },
      "outputs": [],
      "source": [
        "max_length = max(len(seq) for seq in eng_seq + fr_seq)\n",
        "eng_seq_padded = pad_sequences(eng_seq, maxlen=max_length, padding='post')\n",
        "fr_seq_padded = pad_sequences(fr_seq, maxlen=max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "42b188ae",
      "metadata": {
        "id": "42b188ae"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256 # Dimension of the embedding space\n",
        "units = 512 # Number of units in the LSTM layers for both the encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1d2e6544",
      "metadata": {
        "id": "1d2e6544"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(max_length,))\n",
        "enc_emb = Embedding(input_dim=vocab_size_eng, output_dim=embedding_dim)(encoder_inputs)\n",
        "encoder_lstm = LSTM(units, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "encoder_states = [state_h, state_c] # Stores the LSTM's final hidden and cell states,\n",
        "                                   #which will be used to initialize the decoder for generating the output sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "922765f6",
      "metadata": {
        "id": "922765f6"
      },
      "outputs": [],
      "source": [
        "decoder_inputs = Input(shape=(max_length,))\n",
        "dec_emb_layer = Embedding(input_dim=vocab_size_fr, output_dim=embedding_dim)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "decoder_lstm = LSTM(units, return_sequences=True, return_state=True) # return_sequences: Whether to return the last output in the output sequence,\n",
        "                                                                    #or the full sequence\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "decoder_dense = Dense(vocab_size_fr, activation='softmax')\n",
        "output = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "85eb4aea",
      "metadata": {
        "id": "85eb4aea"
      },
      "outputs": [],
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1fbdb99e",
      "metadata": {
        "id": "1fbdb99e"
      },
      "outputs": [],
      "source": [
        "X_train, x_temp, y_train, y_temp = train_test_split(eng_seq_padded, fr_seq_padded, test_size=0.2)\n",
        "X_val, X_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "50152887",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50152887",
        "outputId": "d7702003-7278-4631-df95-0c4b1e32430d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m600s\u001b[0m 541ms/step - accuracy: 0.8785 - loss: 1.2244 - val_accuracy: 0.8991 - val_loss: 0.7080\n",
            "Epoch 2/5\n",
            "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m624s\u001b[0m 545ms/step - accuracy: 0.9019 - loss: 0.6682 - val_accuracy: 0.9067 - val_loss: 0.6020\n",
            "Epoch 3/5\n",
            "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 546ms/step - accuracy: 0.9094 - loss: 0.5565 - val_accuracy: 0.9124 - val_loss: 0.5261\n",
            "Epoch 4/5\n",
            "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 559ms/step - accuracy: 0.9153 - loss: 0.4736 - val_accuracy: 0.9166 - val_loss: 0.4797\n",
            "Epoch 5/5\n",
            "\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m609s\u001b[0m 547ms/step - accuracy: 0.9205 - loss: 0.4112 - val_accuracy: 0.9195 - val_loss: 0.4500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79b3613bd210>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit([X_train, X_train], y_train, validation_data=([X_val, X_val], y_val), epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "17699bf6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17699bf6",
        "outputId": "222ac766-cb75-4478-b4b1-504db9bcaf82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m549/549\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 72ms/step - accuracy: 0.9209 - loss: 0.4433\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4443463981151581, 0.9204893112182617]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.evaluate([X_test, X_test], y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "87ba32ce",
      "metadata": {
        "id": "87ba32ce"
      },
      "outputs": [],
      "source": [
        "def translate_sentence(sentence):\n",
        "    seq = tokenizer_eng.texts_to_sequences([sentence])\n",
        "    padded = pad_sequences(seq, maxlen=max_length, padding='post')\n",
        "    translated = np.argmax(model.predict([padded, padded]), axis=-1)\n",
        "\n",
        "    translated_sentence = []\n",
        "    for i in translated[0]:\n",
        "        if i in tokenizer_fr.index_word:\n",
        "            translated_sentence.append(tokenizer_fr.index_word[i])\n",
        "        else:\n",
        "            translated_sentence.append(' ')\n",
        "\n",
        "    return ' '.join(translated_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "56619dc4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56619dc4",
        "outputId": "e6321f21-d6dc-471a-9642-a028567b6898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "Input: I am french.\n",
            "Translated: je suis français français                                                                                                      \n"
          ]
        }
      ],
      "source": [
        "input_sentence = \"I am french.\"\n",
        "translated_sentence = translate_sentence(input_sentence)\n",
        "print(f\"Input: {input_sentence}\")\n",
        "print(f\"Translated: {translated_sentence}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "04e6d0d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04e6d0d3",
        "outputId": "982f92bd-b736-4667-9b24-54cd3921dc7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Input: I love you.\n",
            "Translated: je t'aime                                                                                                          \n"
          ]
        }
      ],
      "source": [
        "input_sentence = \"I love you.\"\n",
        "translated_sentence = translate_sentence(input_sentence)\n",
        "print(f\"Input: {input_sentence}\")\n",
        "print(f\"Translated: {translated_sentence}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "32514069",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32514069",
        "outputId": "6c3bedf4-ef2d-49b0-9c86-c0c965024708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Input: we can go study.\n",
            "Translated: nous pouvons y                                                                                                        \n"
          ]
        }
      ],
      "source": [
        "input_sentence = \"we can go study.\"\n",
        "translated_sentence = translate_sentence(input_sentence)\n",
        "print(f\"Input: {input_sentence}\")\n",
        "print(f\"Translated: {translated_sentence}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "449c22c3",
      "metadata": {
        "id": "449c22c3"
      },
      "outputs": [],
      "source": [
        "# Create directories for model artifacts\n",
        "os.makedirs(\"artifacts/seq2seq\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f3bfcbad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3bfcbad",
        "outputId": "070a3132-e40c-43e7-b713-c641025101ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full model saved to artifacts/seq2seq/model.keras\n"
          ]
        }
      ],
      "source": [
        "# Save the full model\n",
        "model.save(\"artifacts/seq2seq/model.keras\")\n",
        "print(\"Full model saved to artifacts/seq2seq/model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "9d005da7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d005da7",
        "outputId": "f435106c-744c-46fa-a352-9646a947d86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English tokenizer saved to artifacts/seq2seq/tokenizer_eng.json\n",
            "French tokenizer saved to artifacts/seq2seq/tokenizer_fr.json\n",
            "Model metadata saved to artifacts/seq2seq/metadata.json\n",
            "All Seq2Seq model artifacts saved successfully!\n",
            "\n",
            "Testing model loading...\n",
            "Error during loading test: File not found: filepath=artifacts/seq2seq/encoder_model.keras. Please ensure the file is an accessible `.keras` zip file.\n"
          ]
        }
      ],
      "source": [
        "# Save tokenizers\n",
        "with open(\"artifacts/seq2seq/tokenizer_eng.json\", \"w\") as f:\n",
        "    f.write(tokenizer_eng.to_json())\n",
        "print(\"English tokenizer saved to artifacts/seq2seq/tokenizer_eng.json\")\n",
        "\n",
        "with open(\"artifacts/seq2seq/tokenizer_fr.json\", \"w\") as f:\n",
        "    f.write(tokenizer_fr.to_json())\n",
        "print(\"French tokenizer saved to artifacts/seq2seq/tokenizer_fr.json\")\n",
        "\n",
        "# Also save some metadata for later reference\n",
        "metadata = {\n",
        "    \"vocab_size_eng\": vocab_size_eng,\n",
        "    \"vocab_size_fr\": vocab_size_fr,\n",
        "    \"embedding_dim\": embedding_dim,\n",
        "    \"units\": units,\n",
        "    \"max_length\": max_length\n",
        "}\n",
        "\n",
        "with open(\"artifacts/seq2seq/metadata.json\", \"w\") as f:\n",
        "    json.dump(metadata, f)\n",
        "print(\"Model metadata saved to artifacts/seq2seq/metadata.json\")\n",
        "\n",
        "print(\"All Seq2Seq model artifacts saved successfully!\")\n",
        "\n",
        "# Test loading the saved models\n",
        "print(\"\\nTesting model loading...\")\n",
        "try:\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    # Load encoder\n",
        "    loaded_encoder = load_model(\"artifacts/seq2seq/encoder_model.keras\")\n",
        "    print(\"✓ Encoder model loaded successfully\")\n",
        "\n",
        "    # Load decoder\n",
        "    loaded_decoder = load_model(\"artifacts/seq2seq/decoder_model.keras\")\n",
        "    print(\"✓ Decoder model loaded successfully\")\n",
        "\n",
        "    # Load tokenizers\n",
        "    with open(\"artifacts/seq2seq/tokenizer_eng.json\", \"r\") as f:\n",
        "        loaded_tokenizer_eng = tokenizer_from_json(f.read())\n",
        "    print(\"✓ English tokenizer loaded successfully\")\n",
        "\n",
        "    with open(\"artifacts/seq2seq/tokenizer_fr.json\", \"r\") as f:\n",
        "        loaded_tokenizer_fr = tokenizer_from_json(f.read())\n",
        "    print(\"✓ French tokenizer loaded successfully\")\n",
        "\n",
        "    print(\"\\nModel artifacts can be used for inference!\")\n",
        "except Exception as e:\n",
        "    print(f\"Error during loading test: {str(e)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}